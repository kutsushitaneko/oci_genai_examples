{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle Generative AI Service AI Guardrails API サンプルノートブック（Cohere Command A）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、架空のVtuberのストリーミングの文字起こしを模擬したテキストの要約を作成するタスクにおいて、個人識別情報が LLM へ渡されたり、個人識別情報が含まれるテキストが生成された場合に個人識別情報がアプリケーションの出力に含まれないよう、AI Guardrails API を使用して個人識別情報を検知し、アプリケーションコードでそれをマスクする方法を示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境変数設定\n",
    "事前準備として \".env\" ファイルに OCI のコンパートメントID と LLM のモデルID を記載しておきます。\n",
    "- OCI_COMPARTMENT_ID=XXXXXXXXXX の書式でコンパートメントIDを記載\n",
    "- OCI_GENAI_MODEL_ID=xxxxxxxxxx の書式でモデルID を記載（例：cohere.command-a-03-2025）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_= load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PROFILE = \"DEFAULT\" # 構成ファイルに合わせて変更してください。\n",
    "config = oci.config.from_file(file_location='~/.oci/config', profile_name=CONFIG_PROFILE)\n",
    "config[\"region\"] = \"ap-osaka-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id:cohere.command-a-03-2025\n"
     ]
    }
   ],
   "source": [
    "compartment_id = os.getenv(\"OCI_COMPARTMENT_ID\") \n",
    "model_id = os.getenv(\"OCI_GENAI_MODEL_ID\")\n",
    "print(f\"model_id:{model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative AI Service （生成AIサービス）の推論クライアントの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Guardrails を適用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply_guardrails：ガードレールを適用するメソッド [リファレンス](https://docs.oracle.com/en-us/iaas/tools/python/2.153.0/api/generative_ai_inference/client/oci.generative_ai_inference.GenerativeAiInferenceClient.html#oci.generative_ai_inference.GenerativeAiInferenceClient.apply_guardrails)\n",
    "- ApplyGuardrailsDetails：ガードレールへの入力テキストの詳細[リファレンス](https://docs.oracle.com/en-us/iaas/tools/python/2.153.0/api/generative_ai_inference/models/oci.generative_ai_inference.models.ApplyGuardrailsDetails.html)\n",
    "- GuardrailsTextInput：ガードレールへの入力テキストを表現するクラス [リファレンス](https://docs.oracle.com/en-us/iaas/tools/python/2.153.0/api/generative_ai_inference/models/oci.generative_ai_inference.models.GuardrailsTextInput.html)\n",
    "- GuardrailConfigs：ガードレールの構成 [リファレンス](https://docs.oracle.com/en-us/iaas/tools/python/2.153.0/api/generative_ai_inference/models/oci.generative_ai_inference.models.GuardrailConfigs.html)\n",
    "- ContentModerationConfiguration：コンテンツモデレーションの構成[リファレンス](https://docs.oracle.com/en-us/iaas/tools/python/2.153.0/api/generative_ai_inference/models/oci.generative_ai_inference.models.ContentModerationConfiguration.html#oci.generative_ai_inference.models.ContentModerationConfiguration)\n",
    "- 参考：OCI CLI apply-guardrails：[リファレンス](https://docs.oracle.com/en-us/iaas/tools/oci-cli/3.56.1/oci_cli_docs/cmdref/generative-ai-inference/apply-guardrails-result/apply-guardrails.html)\n",
    "- 参考：指定できる PII のタイプは、\"PERSON\",\"ADDRESS\", \"EMAIL\", \"TELEPHONE_NUMBER\" の 4種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opc_request_id: 37534d28-da86-46e8-84eb-00c1d148b2be\n"
     ]
    }
   ],
   "source": [
    "INPUT_TEXT = \"\"\"\n",
    "The following CONTEXT is a transcription of a VTuber's stream. Please follow the user's INSTRUCTIONS based on this CONTEXT.\n",
    "# CONTEXT:\n",
    "Stream Opening:\n",
    "\"Hey there, my amazing viewers! Welcome back to my channel! I'm Ethan Hunt, your favorite virtual agent streaming live from... well, let's just say I'm always on the move! winks Today we're going to be playing some intense stealth games, perfect for someone with my... particular skill set.\"\n",
    "Mid-Stream Segment:\n",
    "\"Oh, I see viewers in the live comments asking about fan mail again! You know what, I've been getting so many requests lately. If you want to send me anything - fan art, letters, or even snacks - you can mail them to my manager's office at 456 Oak Avenue, Los Angeles, CA 90210. Don't worry, it's totally secure... probably more secure than most government facilities, if you know what I mean! mysterious smile\"\n",
    "Game Commentary:\n",
    "\"Alright, time for this stealth mission. You know, this reminds me of that time I had to infiltrate a building using only a paperclip and... wait, I probably shouldn't tell that story on stream. Anyway, let's see if this game's AI is smarter than real security systems!\"\n",
    "Interaction with Chat:\n",
    "\"Someone in the live comments is asking for my contact info for business inquiries. Well, my business manager handles all that stuff - you can reach them at 123-456-7890. And for serious collaboration proposals, shoot an email to ethan.hunt.vtuber@streammail.net. But please, no impossible missions in my DMs... I get enough of those offline! laughs\"\n",
    "Stream Ending:\n",
    "\"That's all for today's stream, agents! Remember to hit that subscribe button and ring the notification bell - think of it as your mission briefing alert! Until next time, this is Ethan Hunt signing off. Your mission, should you choose to accept it, is to stay awesome! This message will self-destruct in... just kidding! See you next stream!\"\n",
    "\n",
    "# INSTRUCTIONS:\n",
    "Please summarize the content of the CONTEXT. Also, list any personally identifiable information contained in the CONTEXT.\n",
    "\"\"\"\n",
    "PII_TYPES = [\"PERSON\",\"ADDRESS\", \"EMAIL\", \"TELEPHONE_NUMBER\"]\n",
    "\n",
    "opc_request_id = str(uuid.uuid4())\n",
    "print(f\"opc_request_id: {opc_request_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_guardrails_response = generative_ai_inference_client.apply_guardrails(\n",
    "    apply_guardrails_details=oci.generative_ai_inference.models.ApplyGuardrailsDetails(\n",
    "        input=oci.generative_ai_inference.models.GuardrailsTextInput(\n",
    "            type=\"TEXT\",\n",
    "            content=INPUT_TEXT,\n",
    "            language_code=\"en\"), # en | es | en-US | zh-CN\n",
    "        guardrail_configs=oci.generative_ai_inference.models.GuardrailConfigs(\n",
    "            personally_identifiable_information_config=oci.generative_ai_inference.models.PersonallyIdentifiableInformationConfiguration(\n",
    "                types=PII_TYPES)),\n",
    "        compartment_id=compartment_id),\n",
    "    opc_request_id=opc_request_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": {\n",
      "    \"content_moderation\": null,\n",
      "    \"personally_identifiable_information\": [\n",
      "      {\n",
      "        \"label\": \"PERSON\",\n",
      "        \"length\": 10,\n",
      "        \"offset\": 216,\n",
      "        \"score\": 0.9978127777576447,\n",
      "        \"text\": \"Ethan Hunt\"\n",
      "      },\n",
      "      {\n",
      "        \"label\": \"ADDRESS\",\n",
      "        \"length\": 37,\n",
      "        \"offset\": 704,\n",
      "        \"score\": 0.9998851087358263,\n",
      "        \"text\": \"456 Oak Avenue, Los Angeles, CA 90210\"\n",
      "      },\n",
      "      {\n",
      "        \"label\": \"TELEPHONE_NUMBER\",\n",
      "        \"length\": 12,\n",
      "        \"offset\": 1344,\n",
      "        \"score\": 0.9998054504394531,\n",
      "        \"text\": \"123-456-7890\"\n",
      "      },\n",
      "      {\n",
      "        \"label\": \"EMAIL\",\n",
      "        \"length\": 32,\n",
      "        \"offset\": 1417,\n",
      "        \"score\": 0.95,\n",
      "        \"text\": \"ethan.hunt.vtuber@streammail.net\"\n",
      "      },\n",
      "      {\n",
      "        \"label\": \"PERSON\",\n",
      "        \"length\": 10,\n",
      "        \"offset\": 1733,\n",
      "        \"score\": 0.9937395751476288,\n",
      "        \"text\": \"Ethan Hunt\"\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_injection\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(apply_guardrails_response.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 個人識別情報マスキング処理\n",
    "※ マスキング処理自体は、AI Guardrails API の機能ではありません。AI Guardrails API は、個人識別情報の検出のみを行います。このマスキング処理コードは、例です。マスクに仕様する文字列は適宜変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "マスクした PII: タイプ=PERSON, テキスト=\"Ethan Hunt\", スコア=0.9937\n",
      "マスクした PII: タイプ=EMAIL, テキスト=\"ethan.hunt.vtuber@streammail.net\", スコア=0.9500\n",
      "マスクした PII: タイプ=TELEPHONE_NUMBER, テキスト=\"123-456-7890\", スコア=0.9998\n",
      "マスクした PII: タイプ=ADDRESS, テキスト=\"456 Oak Avenue, Los Angeles, CA 90210\", スコア=0.9999\n",
      "マスクした PII: タイプ=PERSON, テキスト=\"Ethan Hunt\", スコア=0.9978\n",
      "\\n================================================================================\n",
      "個人情報マスク処理結果:\n",
      "================================================================================\n",
      "\n",
      "The following CONTEXT is a transcription of a VTuber's stream. Please follow the user's INSTRUCTIONS based on this CONTEXT.\n",
      "# CONTEXT:\n",
      "Stream Opening:\n",
      "\"Hey there, my amazing viewers! Welcome back to my channel! I'm ### [PERSON] ###, your favorite virtual agent streaming live from... well, let's just say I'm always on the move! winks Today we're going to be playing some intense stealth games, perfect for someone with my... particular skill set.\"\n",
      "Mid-Stream Segment:\n",
      "\"Oh, I see viewers in the live comments asking about fan mail again! You know what, I've been getting so many requests lately. If you want to send me anything - fan art, letters, or even snacks - you can mail them to my manager's office at ### [ADDRESS] ###. Don't worry, it's totally secure... probably more secure than most government facilities, if you know what I mean! mysterious smile\"\n",
      "Game Commentary:\n",
      "\"Alright, time for this stealth mission. You know, this reminds me of that time I had to infiltrate a building using only a paperclip and... wait, I probably shouldn't tell that story on stream. Anyway, let's see if this game's AI is smarter than real security systems!\"\n",
      "Interaction with Chat:\n",
      "\"Someone in the live comments is asking for my contact info for business inquiries. Well, my business manager handles all that stuff - you can reach them at ### [PHONE] ###. And for serious collaboration proposals, shoot an email to ### [EMAIL] ###. But please, no impossible missions in my DMs... I get enough of those offline! laughs\"\n",
      "Stream Ending:\n",
      "\"That's all for today's stream, agents! Remember to hit that subscribe button and ring the notification bell - think of it as your mission briefing alert! Until next time, this is ### [PERSON] ### signing off. Your mission, should you choose to accept it, is to stay awesome! This message will self-destruct in... just kidding! See you next stream!\"\n",
      "\n",
      "# INSTRUCTIONS:\n",
      "Please summarize the content of the CONTEXT. Also, list any personally identifiable information contained in the CONTEXT.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mask_personal_information(original_text, guardrails_result):\n",
    "    \"\"\"\n",
    "    AI Guardrails API の個人識別情報検出結果を使用して、元のテキストの個人識別情報をマスクします。\n",
    "    \n",
    "    Args:\n",
    "        original_text (str): 元のテキスト\n",
    "        guardrails_result: apply_guardrails の結果\n",
    "    \n",
    "    Returns:\n",
    "        str: 個人識別情報がマスクされたテキスト\n",
    "    \"\"\"\n",
    "    masked_text = original_text\n",
    "    \n",
    "    # 個人情報検出結果を取得\n",
    "    pii_results = guardrails_result.data.results.personally_identifiable_information\n",
    "    \n",
    "    if pii_results:\n",
    "        sorted_pii = sorted(pii_results, key=lambda x: x.offset, reverse=True)\n",
    "        \n",
    "        for pii_item in sorted_pii:\n",
    "            start_pos = pii_item.offset\n",
    "            end_pos = start_pos + pii_item.length\n",
    "            pii_type = pii_item.label\n",
    "            \n",
    "            # マスク文字の指定\n",
    "            if pii_type == \"PERSON\":\n",
    "                mask = \"### [PERSON] ###\"\n",
    "            elif pii_type == \"ADDRESS\":\n",
    "                mask = \"### [ADDRESS] ###\"\n",
    "            elif pii_type == \"EMAIL\":\n",
    "                mask = \"### [EMAIL] ###\"\n",
    "            elif pii_type == \"TELEPHONE_NUMBER\":\n",
    "                mask = \"### [PHONE] ###\"\n",
    "            else:\n",
    "                mask = \"### [PII] ###\"\n",
    "            \n",
    "            # テキストを置換\n",
    "            masked_text = masked_text[:start_pos] + mask + masked_text[end_pos:]\n",
    "            \n",
    "            print(f\"マスクした PII: タイプ={pii_type}, テキスト=\\\"{pii_item.text}\\\", スコア={pii_item.score:.4f}\")\n",
    "    \n",
    "    return masked_text\n",
    "\n",
    "# 個人情報をマスクしたテキストを生成\n",
    "masked_input_text = mask_personal_information(INPUT_TEXT, apply_guardrails_response)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"個人情報マスク処理結果:\")\n",
    "print(\"=\"*80)\n",
    "print(masked_input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マスクされた入力テキストを使用して推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_request = oci.generative_ai_inference.models.CohereChatRequest()\n",
    "chat_request.message = masked_input_text\n",
    "chat_request.max_tokens = 4000\n",
    "chat_request.is_stream = True\n",
    "chat_request.temperature = 0.75\n",
    "chat_request.frequency_penalty = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_detail = oci.generative_ai_inference.models.ChatDetails()\n",
    "\n",
    "chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=model_id)\n",
    "chat_detail.compartment_id = compartment_id\n",
    "chat_detail.chat_request = chat_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = generative_ai_inference_client.chat(chat_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Streaming Chat Response**************************\n",
      "### Summary of the Context:\n",
      "\n",
      "The VTuber, ### [PERSON] ###, begins the stream by welcoming viewers and announcing that they will be playing stealth games, a genre that aligns with their \"particular skill set.\" During the stream, they address viewer questions about fan mail, providing the address of their manager's office for secure deliveries. They also share a humorous anecdote about infiltrating a building with a paperclip, though they refrain from elaborating further. In response to a chat request for business contact information, they provide their manager's phone number and email for serious collaboration proposals, humorously asking viewers to avoid sending \"impossible missions\" via direct messages. The stream concludes with a playful sign-off, encouraging viewers to subscribe and stay tuned for future streams, likening it to a mission briefing.\n",
      "\n",
      "### Personally Identifiable Information (PII) in the Context:\n",
      "1. **Name**: ### [PERSON] ### (Note: This is likely a pseudonym or VTuber persona, but it’s still treated as PII in this context.)  \n",
      "2. **Address**: ### [ADDRESS] ### (Manager's office address for fan mail.)  \n",
      "3. **Phone Number**: ### [PHONE] ### (Business manager's contact number.)  \n",
      "4. **Email**: ### [EMAIL] ### (Email for collaboration proposals.)  \n",
      "\n",
      "These details are highlighted as potentially sensitive information that could identify or contact the VTuber or their associates.\n",
      "\n",
      "**************************Finish Reason************************************\n",
      "finish_reason:COMPLETE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"**************************Streaming Chat Response**************************\")\n",
    "chatbot_message = \"\"\n",
    "finish_reason = \"\"\n",
    "for event in chat_response.data.events():\n",
    "    res = json.loads(event.data)\n",
    "    if 'finishReason' in res.keys():\n",
    "        finish_reason = res['finishReason']\n",
    "        if 'text' in res:\n",
    "            chatbot_message = res['text']\n",
    "        break\n",
    "    if 'text' in res:\n",
    "        print(res['text'], end=\"\", flush=True)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"**************************Finish Reason************************************\")\n",
    "print(f\"finish_reason:{finish_reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論結果に対して AI Guardrails API で 個人識別情報をチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opc_request_id: f6c18996-4d0e-4ffd-9aae-7cd951c2519a\n"
     ]
    }
   ],
   "source": [
    "INPUT_TEXT = chatbot_message\n",
    "PII_TYPES = [\"PERSON\",\"ADDRESS\", \"EMAIL\", \"TELEPHONE_NUMBER\"]\n",
    "\n",
    "opc_request_id = str(uuid.uuid4())\n",
    "print(f\"opc_request_id: {opc_request_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_guardrails_response = generative_ai_inference_client.apply_guardrails(\n",
    "    apply_guardrails_details=oci.generative_ai_inference.models.ApplyGuardrailsDetails(\n",
    "        input=oci.generative_ai_inference.models.GuardrailsTextInput(\n",
    "            type=\"TEXT\",\n",
    "            content=INPUT_TEXT,\n",
    "            language_code=\"en\"), # en | es | en-US | zh-CN\n",
    "        guardrail_configs=oci.generative_ai_inference.models.GuardrailConfigs(\n",
    "            personally_identifiable_information_config=oci.generative_ai_inference.models.PersonallyIdentifiableInformationConfiguration(\n",
    "                types=PII_TYPES)),\n",
    "        compartment_id=compartment_id),\n",
    "    opc_request_id=opc_request_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": {\n",
      "    \"content_moderation\": null,\n",
      "    \"personally_identifiable_information\": null,\n",
      "    \"prompt_injection\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(apply_guardrails_response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n================================================================================\n",
      "個人情報マスク処理結果:\n",
      "================================================================================\n",
      "### Summary of the Context:\n",
      "\n",
      "The VTuber, ### [PERSON] ###, begins the stream by welcoming viewers and announcing that they will be playing stealth games, a genre that aligns with their \"particular skill set.\" During the stream, they address viewer questions about fan mail, providing the address of their manager's office for secure deliveries. They also share a humorous anecdote about infiltrating a building with a paperclip, though they refrain from elaborating further. In response to a chat request for business contact information, they provide their manager's phone number and email for serious collaboration proposals, humorously asking viewers to avoid sending \"impossible missions\" via direct messages. The stream concludes with a playful sign-off, encouraging viewers to subscribe and stay tuned for future streams, likening it to a mission briefing.\n",
      "\n",
      "### Personally Identifiable Information (PII) in the Context:\n",
      "1. **Name**: ### [PERSON] ### (Note: This is likely a pseudonym or VTuber persona, but it’s still treated as PII in this context.)  \n",
      "2. **Address**: ### [ADDRESS] ### (Manager's office address for fan mail.)  \n",
      "3. **Phone Number**: ### [PHONE] ### (Business manager's contact number.)  \n",
      "4. **Email**: ### [EMAIL] ### (Email for collaboration proposals.)  \n",
      "\n",
      "These details are highlighted as potentially sensitive information that could identify or contact the VTuber or their associates.\n"
     ]
    }
   ],
   "source": [
    "# 個人情報をマスクしたテキストを生成\n",
    "masked_input_text = mask_personal_information(INPUT_TEXT, apply_guardrails_response)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"個人情報マスク処理結果:\")\n",
    "print(\"=\"*80)\n",
    "print(masked_input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
